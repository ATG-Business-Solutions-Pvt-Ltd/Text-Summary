# -*- coding: utf-8 -*-
"""Transformers-Summarization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15I0ZMUoTyb36CRv2gyT1zIjm4uYtM4yK
"""
#pip install PyPDF2
#pip install fpdf
#pip install yake
#pip install streamlit
#pip install transformers
#pip install transformers[sentencepiece]

import os
import PyPDF2
import yake
from PIL import Image
import fpdf
import streamlit as st
import os

# Directory for storing PDF files
pdf_directory = '/content/pdf_files'

# Directory for storing extracted text from PDFs
text_directory = '/content/extracted_text'

# Create directories if they don't exist
os.makedirs(text_directory, exist_ok=True)


pdf = fpdf.FPDF(format='letter')
pdf.add_font('Arial', '', '/content/arial.ttf', uni=True) #path of the font file is set to avoid the error generated by U+2019=','
pdf.set_font("Arial", size=12)
pdf.add_page()

# Directory for storing PDF files
pdf_directory = '/content/pdf_files'

# Directory for storing extracted text from PDFs
text_directory = '/content/extracted_text'

# Create directories if they don't exist
os.makedirs(text_directory, exist_ok=True)

def save_uploadedfile(uploadedfile):
  with open(os.path.join(pdf_directory, uploadedfile.name),'wb') as f:
    f.write(uploadedfile.getbuffer())
    return st.success("Saved File: to pdf_directory".format(uploadedfile.name))

#Upload and save PDF in a directory
st.title("PDF File upload")
st.text("A simple way to upload files directly into a directory")
uploadedfiles = st.file_uploader("Upload PDF", type=['pdf'], accept_multiple_files=True)
for file in uploadedfiles:
 if uploadedfiles is not None:
     save_uploadedfile(file)

for file_name in os.listdir(pdf_directory):
    if file_name.endswith('.pdf'):
        # Open the PDF file
        with open(os.path.join(pdf_directory, file_name), 'rb') as file:
            # Create a PDF reader object
            reader = PyPDF2.PdfReader(file)

            # Extract text from each page
            text = ''
            for page in reader.pages:
                text += page.extract_text()

            # Save the extracted text as a text file
            text_file_name = file_name.replace('.pdf', '.txt')
            text_file_path = os.path.join(text_directory, text_file_name)
            with open(text_file_path, 'w') as text_file:
                text_file.write(text)

# Directory for storing PDF documents
pdf_directory = '/content/pdf_files'

if st.button("Key Phrases of PDF"):
  for file_name in os.listdir(pdf_directory):
      if file_name.endswith('.pdf'):
          selected_keys=[]
          # Open the PDF file
          with open(os.path.join(pdf_directory, file_name), 'rb') as file:
              # Create a PDF reader object
              reader = PyPDF2.PdfReader(file)
              # Extract text from each page
              text = ''
             
              for page in reader.pages:
                  text += page.extract_text()
              kw_extractor = yake.KeywordExtractor(top=3, stopwords=None)
              keywords = kw_extractor.extract_keywords(text)
              selected_keys.append(keywords)
         # Print the generated summaries for each pdf
          for j, keys in enumerate(selected_keys):
            st.write(f"Keywords for PDF :")
            for kw, v in keys:
              st.write("Keyphrase: ",kw, ": score", v)   
             

# Directory for storing PDF documents
pdf_directory = '/content/pdf_files'

if st.button("Summarise the text"):
  sample_files = []
  for file_name in os.listdir(pdf_directory):
      if file_name.endswith('.pdf'):
          sample_files.append(os.path.join(pdf_directory, file_name))

  pdf_summaries = []  # To store the generated summaries

  # Loop through each file
  for sample_file in sample_files:
      with open(sample_file, 'rb') as file:
          # Create a PDF reader object
          reader = PyPDF2.PdfReader(file)

          # Extract text from each page
          text = ''
          for page in reader.pages:
              text += page.extract_text()

          from transformers import T5ForConditionalGeneration,T5Tokenizer

          # Initialize the model and tokenizer
          model = T5ForConditionalGeneration.from_pretrained("t5-base")
          tokenizer = T5Tokenizer.from_pretrained("t5-base")

          # Encode the text
          inputs = tokenizer.encode("summarize: " + text,
          return_tensors="pt", max_length=1000,
          truncation=True)

          # Generate the summary
          outputs = model.generate(inputs,
          max_length=1000, min_length=100,
          length_penalty=2.0, num_beams=4,
          early_stopping=True)

          # Decode the summary
          summary = tokenizer.decode(outputs[0])

          pdf_summaries.append(summary)

          pdf.write(5,summary)

          pdf.output("Summarise-T.pdf")

  # Print the generated summaries for each pdf
  for i, summary in enumerate(pdf_summaries):
      st.write(f"Summary for PDF {i+1}:")
      print(summary)
      print()
      st.write('', str(summary).strip('][\''))
      st.download_button('Download PDF',data=summary,file_name='pdf_test.pdf')
   


  